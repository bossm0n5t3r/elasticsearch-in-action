# 3장. 아키텍처

## 3.1 개요

- 자바로 개발된 고성능 풀텍스트 검색 라이브러리인 아파치 루씬은 강력한 검색 및 인덱싱 기능으로 잘 알려져 있다.
- 루씬을 핵심 풀텍스트 검색 라이브러리로 래핑해 확장 가능한 분산형 서버 측 애플리케이션을 구축한다.
- 일래스틱서치는 풀텍스트 검색을 제공하기 위한 중심 요소로 루씬을 사용해 프로그래밍 언어에 구애받지 않는 애플리케이션을 구축했다.
- 그러나 일래스틱서치는 단순한 풀텍스트 검색엔진 그 이상
- 고가용성, 내결함성, 속도를 기본 목표로 하는 성능이 뛰어나고 확장 가능한 최신 검색엔진이다.

### 3.1.1 데이터 입력

- 일래스틱서치가 쿼리에 대한 답변을 제공하려면 먼저 데이터가 필요하다.
- 데이터는 여러 소스에서 데이터베이스에서 추출, 파일시스템에서 복사, 다른 시스템 (실시간 스트리밍 시스템 포함)에서 로드 등 다양한 방법으로 일래스틱서치로 인덱싱할 수 있다.
- 데이터베이스
  - 데이터베이스의 데이터 형태가 일래스틱서치가 기대하는 것과 정확하게 일치하지 않을 수 있으므로 일래스틱서치에 인덱싱하기 전에 ETL(추출, 변환, 적재) 도구를 사용해 데이터를 변환하고 강화할 수 있다.
    - 로그 스태시 등
- 파일 저장소
  - 애플리케이션, 가상 머신 (VM), 데이터베이스 및 기타 시스템은 수많은 로그 및 메트릭 데이터를 뱉어낸다.
  - 검색, 분석, 저장을 위해 이 데이터를 일래스틱서치로 가져와야 한다.
  - 파일비트(Filebeat) 또는 로그스태시 같은 도구를 사용해 검색, 디버그, 분석 목적으로 일래스틱서치에 데이터를 덤프할 수 있다.
- 애플리케이션
  - 로그스태시 같은 일래스틱 스택 구성 요소를 사용하거나 일래스틱서치에 데이터를 게시하는 내부 실시간 스트리밍 라이브러리를 구축할 수 있고 이 데이터는 검색 기능에 사용된다.
- 일래스틱서치는 데이터가 영구 저장소에서 나오거나 실시간으로 내부적으로 분석되고 처리될 것으로 기대한다.
- 검색 및 분석 형태의 분석 프로세스는 데이터를 효율적으로 검색하는데 도움된다.
- 일반적인 설정에서 조직은 ETL 도구를 사용해 데이터를 일래스틱서치로 전송한다.
- 수집된 데이터는 일래스틱서치 저장소를 통해 생성되면 검색 가능하다.

### 3.1.2 데이터 처리

- 일래스틱서치의 기본 정보 단위는 JSON 도큐먼트로 표현된다.

**데이터 수집**

- 일래스틱서치는 최적화 및 압축 기술을 사용해 모든 데이터를 디스크에 저장한다.
- 일래스틱서치에는 비즈니스 데이터 외에도 스토리지가 필요한 클러스터 상태, 트랜잭션 정보 등과 관련된 자체 데이터가 있다.
- 데이터 폴더에 대해 좀 더 자세히 살펴보면 일래스틱서치는 데이터를 노드별, 데이터 타입별로 분류한다.
- 일래스틱서치는 각 데이터 타입을 기반으로 버킷 세트를 생성한다.
- 간단히 말해서 인덱스틑 도큐먼트의 논리적 모음이다.
- 비즈니스 데이터를 보관하는 버킷이다.
- 일래스틱서치의 인덱스는 데이터베이스의 테이블과 같다.
  - 인덱스는 도큐먼트를 샤드에 보관하는 논리적 컬렉션이다.

**데이터 타입**

- 일래스틱서치를 사용하면 풍부한 데이터 타입을 지원해 도큐먼트를 인덱싱할 수 있다.
- 매핑 (mapping) 이라는 프로세스는 JSON 데이터 타입을 적절한 일래스틱서치 데이터 타입으로 변환한다.
- 매핑은 스키마 정의를 사용해 일래스틱서치에 데이터 필드 처리 방법을 알려준다.
- 데이터를 인덱싱하는 동안 일래스틱서치는 들어오는 데이터를 필드별로 분석한다.
- 매핑 정의를 기반으로 한 고급 알고리즘을 사용해 개별 필드를 분석한다.
- 텍스트 분석은 원시 데이터를 일래스틱서치가 수많은 쿼리를 지원하면서 효율적으로 데이터를 검색할 수 있는 형식으로 변환하는 중요한 단계다.

**데이터 분석**

- 텍스트 분석 단계에서는 텍스트로 표현된 데이터가 분석된다.
- 텍스트는 일련의 규칙을 사용해 단어(토큰)로 분류된다.
- 기본적으로 분석 프로세스 중에는 토큰화 (tokenization) 와 정규화 (normalization) 라는 두 가지 프로세스가 발생한다.
- 토큰화는 일련의 규칙에 따라 텍스트를 토큰으로 나누는 프로세스다.
- 텍스트를 토큰으로 변환하지 않고 그대로 덤프한다면 검색 조건을 일치시키기 어려울 것
- 토큰화 중에 일래스틱서치는 토큰(개별 단어)을 유지하지만 이를 향상 (enhance), 강화 (enrich) 또는 변환 (transform) 하진 않는다.
  - 즉, 토큰은 그대로 유지된다.
- 정규화는 토큰에 대한 추가 데이터를 생성해 풍부한 사용자 경험을 구축하는 데 도움을 준다.
- 다음처럼 토큰을 어근 단위로 축소(어간 추출)하거나 해당 단어의 동의어를 만드는 프로세스다.
- 정규화는 또한 토큰의 동의어 목록을 작성하는 데 도움돼 사용자의 검색 경험을 다시 풍부하게 할 수 있다.
- 토큰과 함께 어근, 동의어 등이 역인덱스라는 고급 데이터 구조에 저장된다.
- 데이터가 분석되면 지속성을 위해 특정 데이터 노드로 전송된다.
- 일반적으로 텍스트 분석 (analysis), 저장 (persistence), 데이터 복제 (replication) 등은 1초도 안 되는 짧은 시간 안에 수행되므로 일래스틱서치가 인덱싱된 후 1초 이내에 데이터를
  사용할 준비가 된다.
  - 일래스틱서치가 보증하는 서비스 수준 협약 SLA

### 3.1.3 데이터 출력

- 데이터가 일래스틱서치에 수집, 분석 및 저장된 후 검색 및 분석 쿼리를 통해 검색된다.
- 검색은 지정된 쿼리에 대해 일치하는 데이터를 가져오고, 분석은 데이터를 수집해 요약된 통계를 형성한다.
- 검색은 정확한 단어 대 단어 일치뿐만 아니라, 어근, 동의어, 철자 오류 등도 찾는다.
- 검색 쿼리가 실행될 때 필드가 풀텍스트 필드인 경우 필드가 인덱싱될 때 수행된 것과 유사한 분석 단계를 거친다.
- 즉, 쿼리는 해당 필드와 연결된 동일한 분석기를 사용해 토큰화되고 정규화된다.
- 각 토큰을 역인덱스에서 검색해 일치시키고, 일치된 결과를 클라이언트에 다시 전달한다.

## 3.2 빌딩 블록

### 3.2.1 도큐먼트

### 3.2.2 인덱스

### 3.2.3 데이터 스트림

### 3.2.4 샤드와 복제본

### 3.2.5 노드와 클러스터

## 3.3 역인덱스

## 3.4 관련성

### 3.4.1 관련성 점수

### 3.4.2 관련성(유사성) 알고리즘

## 3.5 라우팅 알고리즘

## 3.6 스케일링

### 3.6.1 스케일 업 (Scale Up, 수직 확장)

### 3.6.2 스케일 아웃 (Scale Out, 수평 확장)

## 요약
