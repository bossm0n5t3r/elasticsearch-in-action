# 3장. 아키텍처

## 3.1 개요

- 자바로 개발된 고성능 풀텍스트 검색 라이브러리인 아파치 루씬은 강력한 검색 및 인덱싱 기능으로 잘 알려져 있다.
- 루씬을 핵심 풀텍스트 검색 라이브러리로 래핑해 확장 가능한 분산형 서버 측 애플리케이션을 구축한다.
- 일래스틱서치는 풀텍스트 검색을 제공하기 위한 중심 요소로 루씬을 사용해 프로그래밍 언어에 구애받지 않는 애플리케이션을 구축했다.
- 그러나 일래스틱서치는 단순한 풀텍스트 검색엔진 그 이상
- 고가용성, 내결함성, 속도를 기본 목표로 하는 성능이 뛰어나고 확장 가능한 최신 검색엔진이다.

### 3.1.1 데이터 입력

- 일래스틱서치가 쿼리에 대한 답변을 제공하려면 먼저 데이터가 필요하다.
- 데이터는 여러 소스에서 데이터베이스에서 추출, 파일시스템에서 복사, 다른 시스템 (실시간 스트리밍 시스템 포함)에서 로드 등 다양한 방법으로 일래스틱서치로 인덱싱할 수 있다.
- 데이터베이스
  - 데이터베이스의 데이터 형태가 일래스틱서치가 기대하는 것과 정확하게 일치하지 않을 수 있으므로 일래스틱서치에 인덱싱하기 전에 ETL(추출, 변환, 적재) 도구를 사용해 데이터를 변환하고 강화할 수 있다.
    - 로그 스태시 등
- 파일 저장소
  - 애플리케이션, 가상 머신 (VM), 데이터베이스 및 기타 시스템은 수많은 로그 및 메트릭 데이터를 뱉어낸다.
  - 검색, 분석, 저장을 위해 이 데이터를 일래스틱서치로 가져와야 한다.
  - 파일비트(Filebeat) 또는 로그스태시 같은 도구를 사용해 검색, 디버그, 분석 목적으로 일래스틱서치에 데이터를 덤프할 수 있다.
- 애플리케이션
  - 로그스태시 같은 일래스틱 스택 구성 요소를 사용하거나 일래스틱서치에 데이터를 게시하는 내부 실시간 스트리밍 라이브러리를 구축할 수 있고 이 데이터는 검색 기능에 사용된다.
- 일래스틱서치는 데이터가 영구 저장소에서 나오거나 실시간으로 내부적으로 분석되고 처리될 것으로 기대한다.
- 검색 및 분석 형태의 분석 프로세스는 데이터를 효율적으로 검색하는데 도움된다.
- 일반적인 설정에서 조직은 ETL 도구를 사용해 데이터를 일래스틱서치로 전송한다.
- 수집된 데이터는 일래스틱서치 저장소를 통해 생성되면 검색 가능하다.

### 3.1.2 데이터 처리

- 일래스틱서치의 기본 정보 단위는 JSON 도큐먼트로 표현된다.

**데이터 수집**

- 일래스틱서치는 최적화 및 압축 기술을 사용해 모든 데이터를 디스크에 저장한다.
- 일래스틱서치에는 비즈니스 데이터 외에도 스토리지가 필요한 클러스터 상태, 트랜잭션 정보 등과 관련된 자체 데이터가 있다.
- 데이터 폴더에 대해 좀 더 자세히 살펴보면 일래스틱서치는 데이터를 노드별, 데이터 타입별로 분류한다.
- 일래스틱서치는 각 데이터 타입을 기반으로 버킷 세트를 생성한다.
- 간단히 말해서 인덱스틑 도큐먼트의 논리적 모음이다.
- 비즈니스 데이터를 보관하는 버킷이다.
- 일래스틱서치의 인덱스는 데이터베이스의 테이블과 같다.
  - 인덱스는 도큐먼트를 샤드에 보관하는 논리적 컬렉션이다.

**데이터 타입**

- 일래스틱서치를 사용하면 풍부한 데이터 타입을 지원해 도큐먼트를 인덱싱할 수 있다.
- 매핑 (mapping) 이라는 프로세스는 JSON 데이터 타입을 적절한 일래스틱서치 데이터 타입으로 변환한다.
- 매핑은 스키마 정의를 사용해 일래스틱서치에 데이터 필드 처리 방법을 알려준다.
- 데이터를 인덱싱하는 동안 일래스틱서치는 들어오는 데이터를 필드별로 분석한다.
- 매핑 정의를 기반으로 한 고급 알고리즘을 사용해 개별 필드를 분석한다.
- 텍스트 분석은 원시 데이터를 일래스틱서치가 수많은 쿼리를 지원하면서 효율적으로 데이터를 검색할 수 있는 형식으로 변환하는 중요한 단계다.

**데이터 분석**

- 텍스트 분석 단계에서는 텍스트로 표현된 데이터가 분석된다.
- 텍스트는 일련의 규칙을 사용해 단어(토큰)로 분류된다.
- 기본적으로 분석 프로세스 중에는 토큰화 (tokenization) 와 정규화 (normalization) 라는 두 가지 프로세스가 발생한다.
- 토큰화는 일련의 규칙에 따라 텍스트를 토큰으로 나누는 프로세스다.
- 텍스트를 토큰으로 변환하지 않고 그대로 덤프한다면 검색 조건을 일치시키기 어려울 것
- 토큰화 중에 일래스틱서치는 토큰(개별 단어)을 유지하지만 이를 향상 (enhance), 강화 (enrich) 또는 변환 (transform) 하진 않는다.
  - 즉, 토큰은 그대로 유지된다.
- 정규화는 토큰에 대한 추가 데이터를 생성해 풍부한 사용자 경험을 구축하는 데 도움을 준다.
- 다음처럼 토큰을 어근 단위로 축소(어간 추출)하거나 해당 단어의 동의어를 만드는 프로세스다.
- 정규화는 또한 토큰의 동의어 목록을 작성하는 데 도움돼 사용자의 검색 경험을 다시 풍부하게 할 수 있다.
- 토큰과 함께 어근, 동의어 등이 역인덱스라는 고급 데이터 구조에 저장된다.
- 데이터가 분석되면 지속성을 위해 특정 데이터 노드로 전송된다.
- 일반적으로 텍스트 분석 (analysis), 저장 (persistence), 데이터 복제 (replication) 등은 1초도 안 되는 짧은 시간 안에 수행되므로 일래스틱서치가 인덱싱된 후 1초 이내에 데이터를
  사용할 준비가 된다.
  - 일래스틱서치가 보증하는 서비스 수준 협약 SLA

### 3.1.3 데이터 출력

- 데이터가 일래스틱서치에 수집, 분석 및 저장된 후 검색 및 분석 쿼리를 통해 검색된다.
- 검색은 지정된 쿼리에 대해 일치하는 데이터를 가져오고, 분석은 데이터를 수집해 요약된 통계를 형성한다.
- 검색은 정확한 단어 대 단어 일치뿐만 아니라, 어근, 동의어, 철자 오류 등도 찾는다.
- 검색 쿼리가 실행될 때 필드가 풀텍스트 필드인 경우 필드가 인덱싱될 때 수행된 것과 유사한 분석 단계를 거친다.
- 즉, 쿼리는 해당 필드와 연결된 동일한 분석기를 사용해 토큰화되고 정규화된다.
- 각 토큰을 역인덱스에서 검색해 일치시키고, 일치된 결과를 클라이언트에 다시 전달한다.

## 3.2 빌딩 블록

### 3.2.1 도큐먼트

- 도큐먼트 (document) 는 일래스틱서치가 저장을 위해 인덱싱한 정보의 기본 단위다.
- 일래스틱서치에서는 JSON 형식의 도큐먼트를 기대한다.
- 이는 데이터를 키-값 쌍으로 나타낸다.

**도큐먼트 데이터 구문 분석**

- 일래스틱서치는 JSON 파서를 사용해 인덱스에서 사용 가능한 매핑 규칙에 따라 데이터를 적절한 타입으로 역마샬링 (unmarchal) 한다.
- 각 인덱스에는 도큐먼트가 인덱싱되거나 검색 쿼리가 실행될 때 일래스틱서치가 적용하는 일련의 매핑 규칙이 있다.
- 일래스틱서치는 JSON 도큐먼트에서 값을 읽고 분석 및 저장을 위해 특정 데이터 타입으로 변환한다.
- JSON 이 데이터 중첩을 지원하는 것처럼 일래스틱서치도 중첩된 데이터 구조를 지원한다.

**관계형 데이터베이스 비유**

- 일래스틱서치는 다른 데이터베이스와 마찬가지로 저장 서버로 사용될 수 있다는 점을 기억하자.
- 데이터베이스 구조는 관계형인 반면, 일래스틱서치의 구조는 비정규화되고 비관계형이다.
- 일래스틱서치의 도큐먼트는 관계가 없는 독립된 정보로 구성된다.
- 테이블에 여러 레코드를 삽입할 수 있는 것처럼 여러 JSON 도큐먼트를 일래스틱서치에 인덱싱할 수 있다.
- 스키마리스 (schema-less) 기능은 테스트나 개발 중에는 유용하지만 프로덕션 환경에서는 문제가 될 수도 있다.

**도큐먼트 작업 API**

- 도큐먼트 API 에는 두 가지 유형이 있다.
  - 단일 도큐먼트에 대해 작업하는 것
  - 동시에 여러 도큐먼트에 대해 작업 (일괄 작업) 하는 것
- 단일 도큐먼트 API
  - 개발 도큐먼트에 대한 작업을 하나씩 수행한다.
- 다중 도큐먼트 API
  - 여러 도큐먼트를 동시에 작업한다.

### 3.2.2 인덱스

- 저장소에 도큐먼트를 호스팅하려면 컨테이너가 필요하다.
- 이를 위해 일래스틱서치는 도큐먼트의 논리적 컬렉션으로 인덱스를 생성한다.
- 단, 인덱스는 물리적 저장 장소가 아니라 논리적인 그룹이다.
- 샤드는 데이터를 저장소에 들어오고 나가는 데 있어 뒤에서 일하는 역할을 하는 아파치 루씬의 물리적 인스턴스다.
  - 즉, 샤드는 데이터의 물리적 저장과 검색을 담당한다.
- 샤드는 기본 샤드와 복제본 샤드로 분류될 수 있다.
  - 기본 샤드
    - 도큐먼트를 보관
  - 복제본 샤드
    - 기본 샤드의 복사본
- 실제 프로덕션 환경에서는 각 샤드에 대해 여러 개의 복사본을 생성한다.
- 복제본은 데이터 복사본을 보관해 시스템의 중복성을 높이고 검색 쿼리 속도를 높이는 데 도움을 준다.
- 인덱스는 여러 도큐먼트를 보유할 수 있으므로 필요에 맞는 최적의 크기를 찾는 것이 좋다.
- 각 인덱스는 단일 노드에 존재하거나 클러스터의 여러 노드에 분산될 수 있다.
- 모든 인덱스에는 mappings, settings, aliases 같은 속성이 있다.
  - mappings
    - 스키마를 정의하는 프로세스
  - settings
    - 샤드와 복제본을 구성할 수 있다.
  - aliases
    - 단일 인덱스 또는 인덱스 집합에 부여되는 대체 이름

### 3.2.3 데이터 스트림

- 인덱스는 데이터를 보유하고 수집한다.
- 시간이 지나면서 더 많은 데이터가 축적되고 저장되면서 규모가 커질 수 있다.
- 노드를 추가하면 더 많은 노드에 샤드를 분산시켜 이 문제를 완화할 수 있다.
- 이러한 데이터는 정기적으로 (매시간, 매일, 매월) 새로운 인덱스로 롤오버될 필요는 없다.
- 시계열 데이터는 시간에 민감하고 시간 종속적이다.
- 일래스틱서치에 로그 데이터를 보관하려면 주기적으로 변경 및 롤오버되는 데이터를 인덱싱하는 전략을 재고해야 한다.
- 별칭 (alias) 는 단일 인덱스 또는 여러 인덱스의 집합에 대한 대체 이름
- 여러 인덱스를 검색하는 이상적인 방법은 해당 인덱스를 가리키는 별칭을 만드는 것

**시계열 데이터**

- 데이터 스트림은 일래스틱서치에서 시계열 데이터를 수용하며, 여러 인덱스에 데이터를 보관하면서도 검색 및 분석 관련 쿼리를 위해 단일 리소스로 접근할 수 있게 해 준다.
- 날짜 또는 시간 축에 태그가 지정된 데이터는 시간별 인덱스에서 호스팅될 것으로 예상된다.
- 높은 수준에서 이러한 인덱스를 데이터 스트림이라고 한다.
- 그 이면에는 각 데이터 스트림에 각 시점에 대한 인덱스 세트가 있다.
- 이러한 인덱스는 일래스틱서치에 의해 자동 생성되며 숨겨져 있다.
- 데이터 스트림 자체는 배후에 있는 시계열 (롤링) 숨겨진 인덱스에 대한 별칭에 지나지 않는다.
- 검색 및 읽기 요청은 데이터 스트림의 숨겨진 인덱스 전체에 걸쳐 있지만, 인덱싱 요청은 새 (현재) 인덱스로만 전달된다.

### 3.2.4 샤드와 복제본

- 샤드는 데이터를 보관하고, 지원하는 데이터 구조 (역인덱스)를 생성하고, 쿼리를 관리하고, 일래스틱서치에서 데이터를 분석하는 소프트웨어 구성 요소다.
- 이는 인덱스 생성 중에 인덱스에 할당된 아파치 루씬의 인스턴스다.
- 인덱싱 과정에서 도큐먼트가 샤드로 이동한다.
- 샤드는 도큐먼트를 영속적인 파일시스템에 보관하기 위해 변경할 수 없는 파일 세그먼트를 생성한다.
- 루씬은 도큐먼트를 효율적으로 인덱싱하기 위한 고성능 엔진이다.
- 도큐먼트를 인덱싱할 때 뒤에서 많은 일이 진행되며 루씬은 이 작업을 매우 효율적으로 수행한다.
- 샤드는 가용성과 장애 조치를 위해 클러스터 전체에 분산된다.
- 반면 복제본은 시스템의 중복성을 허용한다.
- 인덱스가 작동 중이면 샤드를 재배치 할 수 없다.
- 그렇게 하면 인덱스의 기존 데이터가 무효화되기 때문이다.
- 샤드의 중복 복제본인 복제본 샤드는 애플리케이션에 중복성과 고가용성을 제공한다.
- 읽기 요청을 처리함으로써 복제본은 피크 시간 동안 읽기 로드를 분산시킬 수 있다.
- 복제본은 중복성 목적을 상실할 수 있으므로 해당 샤드와 동일한 노드에 함께 배치되지 않는다.

**정의**

- 클러스터는 노드의 컬렉션
- 노드는 일래스틱서치 서버의 인스턴스

**샤드 및 복제본 배포**

- 각 샤드는 일정량의 데이터를 보유할 것으로 예상된다.

**샤드 크기 결정**

- 일반적인 질문은 샤드 크기를 정하는 방법
- 모든 경우에 적용되는 정답은 없다.
- 샤드 크기를 조정할 때 고려해야 할 매개변수가 하나 더 있는데 바로 힙 메모리
- 노드에는 메모리 및 디스크 공간과 같은 컴퓨팅 리소스가 제한돼 있다.
- 힙 메모리 기가바이트 당 최대 20개의 샤드를 호스팅하는 것이 좋다.
- 핵심은 샤드가 데이터를 저장하므로, 적절한 크기를 정하기 위해 초기 작업을 제대로 수행해야 한다는 점
- 운영 중인 인덱스는 샤드를 수정할 수 없다.
  - 인덱스가 생성돼 작동 중인 후에는 샤드 수를 변경할 수 없다.
  - 도큐먼트는 라우팅 알고리즘에 따라 특정 샤드에 보관된다.

### 3.2.5 노드와 클러스터

**단일 노드 클러스터**

- 노드를 처음 부팅하면 일래스틱서치는 일반적으로 단일 노드 클러스터라고 하는 새 클러스터를 형성한다.
- 클러스터는 스케일 업(수직 확장) 또는 스케일 아웃(수형 확장)해 확장할 수 잇다.
- 클러스터에 더 많은 노드를 추가하면 중복성이 생기고 시스템 내결함성이 향상될 뿐만 아니라 엄청난 성능 이점도 얻을 수 있다.
- 그렇다면 샤드의 관점에서 노드를 추가하면 어떤 이점이 있을까?
  - 일반적으로 데이터는 기존 인덱스에서 새 인덱스로 다시 인덱싱할 수 있다.
  - 새 노드를 고려해 새 인덱스의 샤드 수를 구성할 수 있다.

**노드 역할**

- 모든 노드는 코디네이터부터 데이터 관리, 마스터가 되는 등 다양한 역할을 수행한다.
- 마스터 노드
  - 인덱스 생성 및 삭제, 노드 작업, 클러스터 관리를 위한 기타 관리 관련 작업과 같은 상위 수준 작업에 관여한다.
  - 전체 클러스터에는 마스터 하나만 충분하다.
  - 마스터 노드가 실패하면 클러스터는 다른 노드 중 하나를 마스터로 선출해 바통을 넘긴다.
  - 마스터 노드는 도큐먼트 CRUD 작업에 참여하지 않으며 도큐먼트의 위치를 알고 있다.
- 데이터 노드
  - 인덱싱, 검색, 삭제 및 기타 도큐먼트 관련 작업이 수행되는 곳
  - CRUD 작업 중에 디스크와 자주 통신
  - 따라서 디스크 I/O 및 메모리 집약적인 작업
- 수집 노드
  - ingest 노드
  - 인덱싱이 시작되기 전에 변환 및 강화와 같은 수집 작업을 처리
- 코디네이터 노드
  - 사용자 개입에 관계없이 모든 노드가 수행하는 특별한 역할이 코디네이터 노드
  - 코디네이터는 클라이언트 요청을 끝까지 관리한다.

**역할 구성**

- 개발 모드에서 일래스틱서치를 시작하면 노드는 기본적으로 master, data 및 ingest 역할로 설정된다.
- 노드에서 역할을 구성하려면 elasticsearch.yml 구성 파일에서 node.roles 설정을 조정하기만 하면 된다.
- 설정은 역할 목록을 사용한다.

## 3.3 역인덱스

- 인덱싱 단계 동안 각 풀텍스트 필드에 대해 역인덱스라는 데이터 구조를 사용
- 높은 수준에서 역인덱스는 사전과 매우 유사한 데이터 구조이지만, 단어와 해당 단어가 존재하는 도큐먼트 목록이 모두 포함돼 있다.
- 이 역인덱스는 풀텍스트 검색 단계에서 도큐먼트를 더 빠르게 검색할 수 있는 열쇠
- 풀텍스트 필드로 구성된 각 도큐먼트에 대해 서버는 각각의 역인덱스를 만든다.
- 역인덱스는 더 빠른 정보 검색을 위해 최적화돼 있지만, 분석이 더 복잡해지고 더 많은 공간을 필요로 한다.
- 인덱싱 활동이 증가함에 따라 역인덱스가 증가하므로 컴퓨팅 리소스와 힙 공간을 소비한다.
- 역인덱스는 관련성 점수를 추론하는 데도 도움이 된다.

## 3.4 관련성

- 최신 검색 엔진은 쿼리 조건에 따라 결과를 반환할 뿐만 아니라 가장 관련성이 높은 결과를 분석하고 반환한다.

### 3.4.1 관련성 점수

- 관련성은 검색 결과의 순위를 결정하는 양의 부동 소수점 숫자
- 일래스틱서치는 기본적으로 BM25 (Best Match 25) 관련성 알고리즘을 사용해 반환 결과의 점수를 매기므로 클라이언트가 관련 결과를 기대할 수 있다.
- 이는 이전에 사용된 TF/IDF (Term-Frequency/Inverse Document Frequency) 유사성 알고리즘의 고급 버전
- 관련성 점수는 사용된 유사성 알고리즘에 따라 생성됨

### 3.4.2 관련성(유사성) 알고리즘

- 일래스틱서치는 여러 관련성 알고리즘을 사용하며 기본값은 BM25다.
- BM25와 TF-IDF는 둘 다 도큐먼트 점수 매기기 및 순위 지정을 위해 일래스틱서치에서 사용되는 관련성 알고리즘이지만, 텀 가중치와 도큐먼트 점수를 계산하는 방법이 다르다.
- TF-IDF
  - Term-Frequency/Inverse Document Frequency
  - 알고리즘은 단어 빈도 (TF)와 역도큐먼트 빈도 (IDF)를 기반으로 도큐먼트의 단어에 가중치를 할당하는 전통적인 가중치 방식
  - TF는 도큐먼트에 단어가 나타나는 횟수
  - IDF는 전체 도큐먼트 집합에서 단어가 얼마나 흔하거나 희귀한지를 측정한 것
  - 특정 도큐먼트에서 더 자주 발생하고 전체 컬렉션에서 덜 자주 발생하는 단어는 TF-IDF 알고리즘에 따라 더 관련성이 높은 것으로 간주돼야 한다.
- BM25
  - 알고리즘은 TF-IDF 알고리즘보다 개선됨
  - 매우 반복적인 단어가 지나치게 높은 점수를 받는 것을 방지하기 위해 단어 빈도에 대한 비선형 함수를 사용한다는 점에서 기본 알고리즘에 두 가지 중요한 수정 사항을 도입한다.
  - 또한 긴 도큐먼트에 대한 편향에 대응하기 위해 도큐먼트 길이 정규화 요소를 사용한다.
- 일래스틱서치는 기본값이 요구 사항에 적합하지 않은 경우 가장 적절한 알고리즘을 적용할 수 있는 유사성이라는 모듈을 제공한다.

**Okapi BM25 알고리즘**

- 관련성 점수와 결과를 연관시키는 데에는 단어 빈도 (TF), 역도큐먼트 빈도 (IDF) 및 필드 길이 표준이라는 세 가지 주요 요소가 관련된다.

**유사성 알고리즘 구성**

- 일래스틱서치를 사용하면 기본 BM25가 요구 사항에 맞지 않는 경우 다른 유사성 알고리즘을 연결할 수 있다.

## 3.5 라우팅 알고리즘

- 모든 도큐먼트에는 영구적인 홈(home)이 있다.
- 즉, 특정 기본 샤드에 속해야 한다.
- 일래스틱서치는 인덱싱 시 라우팅 알고리즘을 사용해 도큐먼트를 기본 샤드에 배포한다.
- 라우팅은 도큐먼트의 홈을 특정 샤드에 할당하는 프로세스이며, 각 도큐먼트는 하나의 기본 샤드에만 저장된다.
- 동일한 라우팅 기능을 사용해 해당 도큐먼트가 속한 샤드를 찾기 때문에 동일한 도큐먼트를 검색하는 것이 쉽다.
- 라우팅 알고리즘은 일래스틱서치가 인덱싱 또는 검색 중에 도큐먼트의 샤드를 추론하는데 사용하는 간단한 공식이다.
- `shard_number = hash(id) % number_of_shards`

## 3.6 스케일링

- 셰이 배넌과 그의 팀이 일래스틱서치를 처음부터 다시 작성했을 때 그들의 목표 중 하나는 서버를 쉽게 확장하는 것

### 3.6.1 스케일 업 (Scale Up, 수직 확장)

### 3.6.2 스케일 아웃 (Scale Out, 수평 확장)

## 요약
